{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Derivative:\n",
    "    \"\"\" Enabling the usage of +, *, -, etc. \"\"\"\n",
    "    def __add__(self, other):\n",
    "        return Add(self, other)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return rAdd(self, other)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return Sub(self, other)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return rSub(self, other)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return Mul(self, other)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return rMul(self, other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return Div(self, other)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return rDiv(self, other)\n",
    "   \n",
    "    def Sin(self):\n",
    "        return Sin(self)\n",
    "    \n",
    "    def __pow__(self, power):\n",
    "        return Pow(self, power)\n",
    "    \n",
    "    def Exp(self):\n",
    "        return Exp(self)\n",
    "    \n",
    "    def Cdf(self):\n",
    "        return Cdf(self)\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return Ge(self, other)\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return Le(self, other)\n",
    "    \n",
    "    def __hash__(self):                 # we need this for creating the dictionary with keys as Derivatives object\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Var(Derivative):\n",
    "    \"\"\" A leaf node (a node which doesn't have any child) \"\"\"\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value      # the scalar value of the node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Derivative):\n",
    "    \"\"\" The node that results from adding two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float, np.ndarray)): \n",
    "            self.value = node_a + node_b.value\n",
    "            self.grad = [(node_b, 1)]\n",
    "        elif isinstance(node_b, (int, float, np.ndarray)): \n",
    "            self.value = node_a.value + node_b\n",
    "            self.grad = [(node_a, 1)]\n",
    "        else:      \n",
    "            self.value = node_a.value + node_b.value    # value of the node\n",
    "            self.grad = [(node_a, 1), (node_b, 1)]      # partial derivatives of nodes - value 1 for derivative in respect to node_a and 1 for node_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rAdd(Derivative):\n",
    "    \"\"\" The node that results from adding two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_b, (int, float)): \n",
    "            self.value = node_b + node_a.value\n",
    "            self.grad = [(node_a, 1)]\n",
    "        elif isinstance(node_a, (int, float)): \n",
    "            self.value = node_b.value + node_a\n",
    "            self.grad = [(node_b, 1)]\n",
    "        else:      \n",
    "            self.value = node_b.value + node_a.value    # value of the node\n",
    "            self.grad = [(node_b, 1), (node_a, 1)]      # partial derivatives of nodes - value 1 for derivative in respect to node_a and 1 for node_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substract the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sub(Derivative):\n",
    "    \"\"\" The node that results from subtracting two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a - node_b.value\n",
    "            self.grad = [(node_b, -1)]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value - node_b\n",
    "            self.grad = [(node_a, 1)]\n",
    "        else:      \n",
    "            self.value = node_a.value - node_b.value    # value of the node\n",
    "            self.grad = [(node_a, 1), (node_b, -1)]     # partial derivatives of nodes - should have again the structure as [(node_a, value), (node_b, value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rSub(Derivative):\n",
    "    \"\"\" The node that results from subtracting two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_b, (int, float)): \n",
    "            self.value = node_b - node_a.value\n",
    "            self.grad = [(node_a, -1)]\n",
    "        elif isinstance(node_a, (int, float)): \n",
    "            self.value = node_b.value - node_a\n",
    "            self.grad = [(node_b, 1)]\n",
    "        else:      \n",
    "            self.value = node_b.value - node_a.value    # value of the node\n",
    "            self.grad = [(node_b, 1), (node_a, -1)]     # partial derivatives of nodes - should have again the structure as [(node_a, value), (node_b, value)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul(Derivative):\n",
    "    \"\"\" The node that results from multiplying two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float, np.ndarray)): \n",
    "            self.value = node_a * node_b.value\n",
    "            self.grad = [(node_b, node_a)]\n",
    "        elif isinstance(node_b, (int, float, np.ndarray)): \n",
    "            self.value = node_a.value * node_b\n",
    "            self.grad = [(node_a, node_b)]\n",
    "        else:      \n",
    "            self.value = node_a.value * node_b.value\n",
    "            self.grad = [(node_a, node_b.value), (node_b, node_a.value)]        # f = x*y   df / dx = y   df / dy = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rMul(Derivative):\n",
    "    \"\"\" The node that results from multiplying two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_b, (int, float, np.ndarray)): \n",
    "            self.value = node_b * node_a.value\n",
    "            self.grad = [(node_a, node_b)]\n",
    "        elif isinstance(node_a, (int, float, np.ndarray)): \n",
    "            self.value = node_b.value * node_a\n",
    "            self.grad = [(node_b, node_a)]\n",
    "        else:      \n",
    "            self.value = node_b.value * node_a.value\n",
    "            self.grad = [(node_b, node_a.value), (node_a, node_b.value)]                                # f = x*y   df / dx = y   df / dy = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Div(Derivative):\n",
    "    \"\"\" The node that results from dividing one node by another \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a / node_b.value\n",
    "            self.grad = [(node_b, -node_a/(node_b.value**2))]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value / node_b\n",
    "            self.grad = [(node_a, 1/node_b)]\n",
    "        else:      \n",
    "            self.value = node_a.value / node_b.value\n",
    "            self.grad = [(node_a, 1/node_b.value), (node_b, -node_a.value/(node_b.value**2))]           # f = x/y   df / dx = 1/y    df / dy = -x / (y^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rDiv(Derivative):\n",
    "    \"\"\" The node that results from dividing one node by another \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_b, (int, float)): \n",
    "            self.value = node_b / node_a.value\n",
    "            self.grad = [(node_a, -node_b/(node_a.value**2))]\n",
    "        elif isinstance(node_a, (int, float)): \n",
    "            self.value = node_b.value / node_a\n",
    "            self.grad = [(node_b, 1/node_a)]\n",
    "        else:      \n",
    "            self.value = node_b.value / node_a.value\n",
    "            self.grad = [(node_b, 1/node_a.value), (node_a, -node_b.value/(node_a.value**2))]           # f = x/y   df / dx = 1/y    df / dy = -x / (y^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarithm of one mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(Derivative):\n",
    "    \"\"\" The node that results from sin(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.log(node) \n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.log(node.value)                          \n",
    "            self.grad = [(node, 1/node.value)]                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinus of one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(Derivative):\n",
    "    \"\"\" The node that results from sin(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.sin(node) \n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.sin(node.value)                          # use np.sin() function\n",
    "            self.grad = [(node, np.cos(node.value))]                 # only one derivative, since it takes only one node - use np.cos() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosinus of one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cos(Derivative):\n",
    "    \"\"\" The node that results from cos(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.cos(node)\n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.cos(node.value)                          \n",
    "            self.grad = [(node, -np.sin(node.value))]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pow(Derivative):\n",
    "    \"\"\" The node that results as node ^ power \"\"\"\n",
    "    \n",
    "    def __init__(self, node, power):\n",
    "        self.value = node.value**power                                         # reminder of power operation in python: **\n",
    "        self.grad = [(node, power*node.value**(power-1))]                      # (one derivative)    f = x^n   df/dx = n * x ^ (n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(Derivative):\n",
    "    \"\"\" The node that results from exp(node) \"\"\"\n",
    "\n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.exp(node)  \n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.exp(node.value)                         \n",
    "            self.grad = [(node, np.exp(node.value))]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squareroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sqrt(Derivative):\n",
    "    \"\"\" The node that results from sqrt(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.sqrt(node)\n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.sqrt(node.value)                  \n",
    "            self.grad = [(node, 1/(2*np.sqrt(node.value)))]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ a^x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pot(Derivative):\n",
    "    \"\"\" The node that results from a ^ node \"\"\"\n",
    "    \n",
    "    def __init__(self, a, node):\n",
    "        self.value = a**node.value                          \n",
    "        self.grad = [(node, a**node.value * np.log(a))]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cdf(Derivative):\n",
    "    \"\"\" The node that results from cdf(node) \"\"\"\n",
    "\n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = norm.cdf(node) \n",
    "            self.grad = [(node, norm.pdf(node) )]\n",
    "        else:\n",
    "            self.value = norm.cdf(node.value)            \n",
    "            self.grad = [(node, norm.pdf(node.value))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overskrivning af >= og <="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ge(Derivative):\n",
    "    \"\"\" >= \"\"\"\n",
    "            \n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a >= node_b.value\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value >= node_b\n",
    "        else:      \n",
    "            self.value = node_a.value >= node_b.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Le(Derivative):\n",
    "    \"\"\" <= \"\"\"\n",
    "\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a <= node_b.value\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value <= node_b\n",
    "        else:      \n",
    "            self.value = node_a.value <= node_b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function for getting the gradients values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Gradient(parent_node):\n",
    "    \"\"\" Go down the graph, and compute derivative of `parent_node` with respect to each node \"\"\"\n",
    "    \n",
    "    # we will create a dictionary 'gradient' which will have the nodes as keys and its derivatives as values\n",
    "    gradients = defaultdict(lambda: 0)    # initialize the dictionary so when calling a non-existing key the value of 0 is assigned\n",
    "    \n",
    "    # stack will represent the list of tuples (node, node_derivative) \n",
    "    stack = parent_node.grad.copy()     \n",
    "    \n",
    "    while stack:                             # loop for each different branch\n",
    "        # get node and node_derivative from the top of the stack - function pop()\n",
    "        temp = stack.pop()                   \n",
    "        node = temp[0]\n",
    "        node_derivative = temp[1]            \n",
    "        # add to the value of derivative of the node (gradients[node]) value node_derivative\n",
    "        gradients[node] = gradients[node] + node_derivative  \n",
    "        \n",
    "        if not isinstance(node, Var):        # if the node has children, put them onto the stack\n",
    "            # loop for each node in one branch\n",
    "            for child_node, child_node_derivative in node.grad:                   \n",
    "                # append child_node and child_node_derivative * node_derivative to the stack\n",
    "                stack.append((child_node, child_node_derivative * node_derivative))\n",
    "                \n",
    "    return dict(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Black-Scholes (European Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style \n",
    "style.use('ggplot')\n",
    "from scipy.stats import norm\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euro_call(S0, K, T, r, sigma):\n",
    "    d1 = (Log(S0/K)+(r+1/2*(sigma**2))*T)/(sigma*Sqrt(T))\n",
    "    d2 = d1 - sigma*Sqrt(T)\n",
    "    return S0 * Cdf(d1)  - K * Exp((-1)*r * T) * Cdf(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_val = 100\n",
    "K_val = 100\n",
    "T_val = 1\n",
    "r_val = 0.07\n",
    "sigma_val = 0.2\n",
    "n_simulations = 10000\n",
    "n_steps = 1\n",
    "S0 = Var(S0_val)\n",
    "K = Var(K_val)\n",
    "T = Var(T_val)\n",
    "r = Var(r_val)\n",
    "sigma = Var(sigma_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f equals 11.541470170672412\n",
      "The partial derivative of y with respect to S0 = 0.6736447797120796\n",
      "The partial derivative of y with respect to K = -0.5582300780053555\n",
      "The partial derivative of y with respect to T = 7.512880170653974\n",
      "The partial derivative of y with respect to r = 55.82300780053558\n",
      "The partial derivative of y with respect to sigma = 36.05269624616482\n"
     ]
    }
   ],
   "source": [
    "y = euro_call(S0, K, T, r, sigma)\n",
    "gradients = Get_Gradient(y)\n",
    "\n",
    "print('Value of f equals', y.value)\n",
    "print('The partial derivative of y with respect to S0 =', gradients[S0])\n",
    "print('The partial derivative of y with respect to K =', gradients[K])\n",
    "print('The partial derivative of y with respect to T =', gradients[T])\n",
    "print('The partial derivative of y with respect to r =', gradients[r])\n",
    "print('The partial derivative of y with respect to sigma =', gradients[sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing & Adjoints (European Option) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def European_Option_Price_Adjoints(S0, K, T, r, sigma, n_simulations, n_steps):\n",
    "    timeline = np.arange(0, T.value, 1/n_steps)\n",
    "    np.random.seed(123)\n",
    "    Z = np.random.normal (0, 1, size = (n_simulations , len(timeline)))\n",
    "    \n",
    "    def European_Option_Price(S0, K, T, r, sigma, Z):\n",
    "        dt = T/n_steps\n",
    "        d1 = r - (sigma**2) / 2\n",
    "        d2 = d1 * dt + sigma * Sqrt(dt) * Z \n",
    "        S0 = S0 * Exp(d2)\n",
    "        if ((S0 - K).value >= 0) == True:\n",
    "            return (S0 - K) * Exp((-1) * r * T)\n",
    "        else:\n",
    "            return (S0 - K) * 0 * Exp((-1) * r * T)\n",
    "    \n",
    "    price = []\n",
    "    adjoints = defaultdict(int)\n",
    "    \n",
    "    for i in tqdm(Z[:,-1]):\n",
    "        y = European_Option_Price(S0, K, T, r, sigma, i)\n",
    "        gradients = Get_Gradient(y)\n",
    "        price.append(y.value)\n",
    "        adjoints[\"S_\"] += gradients[S0]/n_simulations\n",
    "        adjoints[\"K_\"] += gradients[K]/n_simulations\n",
    "        adjoints[\"T_\"] += gradients[T]/n_simulations\n",
    "        adjoints[\"r_\"] += gradients[r]/n_simulations\n",
    "        adjoints[\"sigma_\"] += gradients[sigma]/n_simulations\n",
    "    \n",
    "    price = np.mean(price)\n",
    "    \n",
    "    return price, adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 7396.23it/s]\n"
     ]
    }
   ],
   "source": [
    "European_Option = European_Option_Price_Adjoints(S0, K, T, r, sigma, n_simulations, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.679930554682997"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "European_Price = European_Option[0]\n",
    "European_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'S_': 0.6808043272079407,\n",
       "             'K_': -0.5640050216610463,\n",
       "             'T_': 7.600638310393247,\n",
       "             'r_': 56.400502166113164,\n",
       "             'sigma_': 36.52603158765489})"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "European_Adjoints = European_Option[1]\n",
    "European_Adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S0_val = 100\n",
    "# K_val = 100\n",
    "# T_val = 1\n",
    "# r_val = 0.07\n",
    "# sigma_val = 0.2\n",
    "# n_simulations = 1000\n",
    "# n_steps = 1\n",
    "# S0 = Var(S0_val)\n",
    "# K = Var(K_val)\n",
    "# T = Var(T_val)\n",
    "# r = Var(r_val)\n",
    "# sigma = Var(sigma_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TEST MED REDUCE()\n",
    "\n",
    "# def European_Option_Price_Adjoints_(S0, K, T, r, sigma, n_simulations, n_steps):\n",
    "#     timeline = np.arange(0, T.value, 1/n_steps)\n",
    "#     np.random.seed(123)\n",
    "#     Z = np.random.normal(0, 1, size = (n_simulations , len(timeline)))\n",
    "    \n",
    "#     def European_Option_Price(S0, K, T, r, sigma, Z, j):\n",
    "#         a = Z\n",
    "#         b = np.ones((n_simulations, n_steps+1))*S0\n",
    "#         b[:,1:] = a\n",
    "#         Z = b\n",
    "#         dt = T/n_steps\n",
    "#         d1 = r - (sigma**2) / 2\n",
    "#         S0 = reduce(lambda F, i: F * Exp(d1 * dt + sigma * Sqrt(dt) * i), Z[j,:])\n",
    "#         if ((S0 - K).value >= 0) == True:\n",
    "#             return (S0 - K) * Exp((-1) * r * T)\n",
    "#         else:\n",
    "#             return (S0 - K) * 0 * Exp((-1) * r * T)\n",
    "    \n",
    "#     price = []\n",
    "#     adjoints = defaultdict(int)\n",
    "    \n",
    "#     for i in tqdm(range(0, n_simulations)):\n",
    "#         y = European_Option_Price(S0, K, T, r, sigma, Z, i)\n",
    "#         gradients = Get_Gradient(y)\n",
    "#         price.append(y.value)\n",
    "#         adjoints[\"S_\"] += gradients[S0]/n_simulations\n",
    "#         adjoints[\"K_\"] += gradients[K]/n_simulations\n",
    "#         adjoints[\"T_\"] += gradients[T]/n_simulations\n",
    "#         adjoints[\"r_\"] += gradients[r]/n_simulations\n",
    "#         adjoints[\"sigma_\"] += gradients[sigma]/n_simulations\n",
    "    \n",
    "#     price = np.mean(price)\n",
    "    \n",
    "#     return price, adjoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Black-Scholes (Asian Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_Price_Asian_Options(S0, K, T, r, sigma):\n",
    "    sqrt3 = Sqrt(3).value\n",
    "    \n",
    "    b = (1/2) * (r - (1/2) * ((sigma / sqrt3)**2))\n",
    "    \n",
    "    d1 = (Log(S0 / K) + (b + (1/2) * ((sigma / sqrt3)**2) ) * T)/ ((sigma / sqrt3) * Sqrt(T))\n",
    "    \n",
    "    d2 = d1 - (sigma / sqrt3)*Sqrt(T)\n",
    "    \n",
    "    return S0 * Exp((b - r) * T) * Cdf(d1) - K * Exp(-(1) * r * T) * Cdf(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_val = 100\n",
    "K_val = 100\n",
    "T_val = 1\n",
    "r_val = 0.07\n",
    "sigma_val = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f equals 6.024544283554853\n",
      "The partial derivative of y with respect to S0 = 0.6063517314661314\n",
      "The partial derivative of y with respect to K = -0.546106288630583\n",
      "The partial derivative of y with respect to T = 3.596224538143864\n",
      "The partial derivative of y with respect to r = 24.29304228975174\n",
      "The partial derivative of y with respect to sigma = 18.95711577861243\n"
     ]
    }
   ],
   "source": [
    "S0 = Var(S0_val)\n",
    "K = Var(K_val)\n",
    "T = Var(T_val)\n",
    "r = Var(r_val)\n",
    "sigma = Var(sigma_val)\n",
    "\n",
    "y = BS_Price_Asian_Options(S0, K, T, r, sigma)\n",
    "\n",
    "gradients = Get_Gradient(y)\n",
    "\n",
    "print('Value of f equals', y.value)\n",
    "print('The partial derivative of y with respect to S0 =', gradients[S0])\n",
    "print('The partial derivative of y with respect to K =', gradients[K])\n",
    "print('The partial derivative of y with respect to T =', gradients[T])\n",
    "print('The partial derivative of y with respect to r =', gradients[r])\n",
    "print('The partial derivative of y with respect to sigma =', gradients[sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing & Adjoints (Asian Option) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_val = 100\n",
    "T_val = 1\n",
    "r_val = 0.07\n",
    "n_simulations = 1000\n",
    "n_steps = 252\n",
    "S0_val = 100\n",
    "sigma_val = 0.2\n",
    "\n",
    "K = Var(K_val)\n",
    "T = Var(T_val)\n",
    "r = Var(r_val)\n",
    "S0 = Var(S0_val)\n",
    "sigma = Var(sigma_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Asian_Option_Price_Adjoints_(S0, K, T, r, sigma, n_simulations, n_steps):\n",
    "    timeline = np.arange(0, 1, 1/n_steps)      \n",
    "    Z = np.random.normal (0, 1, size = (n_simulations, len(timeline)))\n",
    "    \n",
    "    def Asian_Option_Price(S0, K, T, r, sigma, Z, j):\n",
    "        dt = T/n_steps\n",
    "        d1 = r - (sigma**2) / 2\n",
    "        F = S0\n",
    "        temp = 0\n",
    "        p = 0\n",
    "    \n",
    "        for i in range(0, n_steps):\n",
    "            p += F\n",
    "            d2 = d1 * dt + sigma * Sqrt(dt) * Z[j,i]\n",
    "            temp = F * Exp(d2)\n",
    "            F = temp\n",
    "        S_T = p / n_steps\n",
    "   \n",
    "        if ((S_T - K).value >= 0) == True: \n",
    "            return (S_T - K) * Exp((-1) * r * T)\n",
    "        else:\n",
    "            return (S_T - K) * 0 * Exp((-1) * r * T)\n",
    "   \n",
    "    price = []\n",
    "    adjoints = defaultdict(int)\n",
    "\n",
    "    for j in tqdm(range(0, n_simulations)):\n",
    "        y = Asian_Option_Price(S0, K, T, r, sigma, Z, j)\n",
    "        price.append(y.value)\n",
    "        gradients = Get_Gradient(y)\n",
    "        adjoints[\"S_\"] += gradients[S0]/n_simulations\n",
    "        adjoints[\"K_\"] += gradients[K]/n_simulations\n",
    "        adjoints[\"T_\"] += gradients[T]/n_simulations\n",
    "        adjoints[\"r_\"] += gradients[r]/n_simulations\n",
    "        adjoints[\"sigma_\"] += gradients[sigma]/n_simulations\n",
    "    \n",
    "    price = np.mean(price)\n",
    "    \n",
    "    return price, adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [24:17<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "Asian_Option = Asian_Option_Price_Adjoints_(S0, K, T, r, sigma, n_simulations, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.815025861207657"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asian_Price = Asian_Option[0]\n",
    "Asian_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'S_': 0.6303837320153634,\n",
       "             'K_': -0.5622334734032888,\n",
       "             'T_': 4.168203541842798,\n",
       "             'r_': 25.548648305612094,\n",
       "             'sigma_': 23.79798160449956})"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asian_Adjoints = Asian_Option[1]\n",
    "Asian_Adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import reduce\n",
    "# import operator\n",
    "\n",
    "# def prod(node_a, node_b):\n",
    "#     if isinstance(node_a, (int, float)) andAsian_Option = Asian_Option_Price_Adjoints_(S0, K, T, r, sigma, n_simulations, n_steps)Asian_Option = Asian_Option_Price_Adjoints_(S0, K, T, r, sigma, n_simulations, n_steps)Asian_Adjoints = Asian_Option[1]\n",
    "Asian_Adjoints isinstance(node_b, (int, float)): \n",
    "#         return reduce(operator.mul, range(node_a, node_b), 1)\n",
    "#     elif isinstance(node_b, (int, float)): \n",
    "#         return reduce(operator.mul, range(node_a.value, node_b), 1)\n",
    "#     elif isinstance(node_a, (int, float)): \n",
    "#         return reduce(operator.mul, range(node_a, node_b.value), 1)\n",
    "#     else: \n",
    "#         return reduce(operator.mul, range(node_a.value, node_b.value), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TEST MED REDUCE()\n",
    "\n",
    "# def Asian_Option_Price_Adjoints_(S0, K, T, r, sigma, n_simulations, n_steps):\n",
    "#     timeline = np.arange(0, 1, 1/n_steps)      \n",
    "#     Z = np.random.normal (0 , 1 , size = (n_simulations , len(timeline)))\n",
    "    \n",
    "#     def Asian_Option_Price(S0, K, T, r, sigma, Z, j):\n",
    "#         dt = T/n_steps\n",
    "#         d1 = r - (sigma**2) / 2\n",
    "#         F = S0\n",
    "#         temp = 0\n",
    "#         p = 0\n",
    "        \n",
    "#         temp0 = reduce(lambda F, i: F * Exp(d1 * dt + sigma * Sqrt(dt) * i), Z[j,:])\n",
    "        \n",
    "# #         for i in range(0, n_steps):\n",
    "# #             p += F\n",
    "# #             d2 = d1 * dt + sigma * Sqrt(dt) * Z[j,i]\n",
    "# #             temp = F * Exp(d2)\n",
    "# #             F = temp\n",
    "\n",
    "#         print(temp0.value)\n",
    "        \n",
    "#         temp0 = temp0*S0\n",
    "#         print(\"ny:\", temp0.value)\n",
    "    \n",
    "#         S_T = temp0**(1/n_steps)\n",
    "   \n",
    "#         if ((S_T - K).value >= 0) == True: \n",
    "#             return (S_T - K) * Exp((-1) * r * T)\n",
    "#         else:\n",
    "#             return (S_T - K) * 0 * Exp((-1) * r * T)\n",
    "   \n",
    "#     price = []\n",
    "#     adjoints = defaultdict(int)\n",
    "\n",
    "#     for j in tqdm(range(0, n_simulations)):\n",
    "#         y = Asian_Option_Price(S0, K, T, r, sigma, Z, j)\n",
    "#         price.append(y.value)\n",
    "# #         gradients = Get_Gradient(y)\n",
    "# #         adjoints[\"S_\"] += gradients[S0]/n_simulations\n",
    "# #         adjoints[\"K_\"] += gradients[K]/n_simulations\n",
    "# #         adjoints[\"T_\"] += gradients[T]/n_simulations\n",
    "# #         adjoints[\"r_\"] += gradients[r]/n_simulations\n",
    "# #         adjoints[\"sigma_\"] += gradients[sigma]/n_simulations\n",
    "    \n",
    "#     price = np.mean(price)\n",
    "    \n",
    "#     return price, adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def CVA_Calculation(R, price, spread, T, n_steps):\n",
    "        t_i = 1/n_steps\n",
    "        lamb = spread/(1-R)\n",
    "        Q = 0\n",
    "        for i in np.arange(0, T.value+t_i, t_i): \n",
    "            q = 1 - Exp((-1)* lamb * i)\n",
    "            Q += q\n",
    "        CVA = (1-R) * price * Q\n",
    "        return CVA\n",
    "\n",
    "# Vi definerer, at q[i] har dimensionen T*n_steps. \n",
    "# Vi antager, at q[i] defineres per år, jf. fx Moody's kreditratings, dvs. n_steps=1.\n",
    "\n",
    "# t_i = T*1/n_steps\n",
    "# Input er kreditspænd, spread. Vi antager, at spread og dvs. lambda er konstant. \n",
    "# Hazard rate er l = spread/(1-R).\n",
    "# Da er q[t] = 1-exp(-l*t_i).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def European_Option_Price_Adjoints_CVA(S0, K, T, r, sigma, n_simulations, n_steps, R, spread):\n",
    "    timeline = np.arange(0, T.value, 1/n_steps)\n",
    "    np.random.seed(123)\n",
    "    Z = np.random.normal (0, 1, size = (n_simulations , len(timeline)))\n",
    "    \n",
    "    def European_Option_Price(S0, K, T, r, sigma, Z):\n",
    "        dt = T/n_steps\n",
    "        d1 = r - (sigma**2) / 2\n",
    "        d2 = d1 * dt + sigma * Sqrt(dt) * Z \n",
    "        S0 = S0 * Exp(d2)\n",
    "        if ((S0 - K).value >= 0) == True:\n",
    "            return (S0 - K) * Exp((-1) * r * T)\n",
    "        else:\n",
    "            return (S0 - K) * 0 * Exp((-1) * r * T)\n",
    "    \n",
    "    def CVA_Calculation(R, price, spread, T, n_steps):\n",
    "        t_i = 1/n_steps\n",
    "        lamb = spread/(1-R)\n",
    "        Q = 0\n",
    "        for i in np.arange(0, T.value + t_i, t_i): \n",
    "            q = 1 - Exp((-1) * lamb * i)\n",
    "            Q += q\n",
    "        CVA = (1-R) * price * Q\n",
    "        return CVA\n",
    "    \n",
    "    price = []\n",
    "    CVA = []\n",
    "    adjoints = defaultdict(int)\n",
    "    \n",
    "    for i in tqdm(Z[:,-1]):\n",
    "        y = European_Option_Price(S0, K, T, r, sigma, i)\n",
    "        price.append(y.value)\n",
    "        z = CVA_Calculation(R, y, spread, T, n_steps)\n",
    "        CVA.append(z.value)\n",
    "        gradients = Get_Gradient(z)\n",
    "        adjoints[\"R_\"] += gradients[R]/n_simulations\n",
    "        adjoints[\"spread_\"] += gradients[spread]/n_simulations\n",
    "        adjoints[\"S_\"] += gradients[S0]/n_simulations\n",
    "        adjoints[\"K_\"] += gradients[K]/n_simulations\n",
    "        adjoints[\"T_\"] += gradients[T]/n_simulations\n",
    "        adjoints[\"r_\"] += gradients[r]/n_simulations\n",
    "        adjoints[\"sigma_\"] += gradients[sigma]/n_simulations\n",
    "    \n",
    "    price = np.mean(price)\n",
    "    CVA = np.mean(CVA)\n",
    "    \n",
    "    return price, CVA, adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_val = 100\n",
    "K_val = 100\n",
    "T_val = 1\n",
    "r_val = 0.07\n",
    "sigma_val = 0.2\n",
    "n_simulations = 100000\n",
    "n_steps = 1\n",
    "\n",
    "R_val = 0.40\n",
    "spread_val = 0.02\n",
    "\n",
    "S0 = Var(S0_val)\n",
    "K = Var(K_val)\n",
    "T = Var(T_val)\n",
    "r = Var(r_val)\n",
    "sigma = Var(sigma_val)\n",
    "\n",
    "R = Var(R_val)\n",
    "spread = Var(spread_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:25<00:00, 3862.68it/s]\n"
     ]
    }
   ],
   "source": [
    "European_Option = European_Option_Price_Adjoints_CVA(S0, K, T, r, sigma, n_simulations, n_steps, R, spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.563321726153035"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "European_Price = European_Option[0]\n",
    "European_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23714567305942622"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "European_CVA = European_Option[1]\n",
    "European_CVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'R_': -0.014945112791514443,\n",
       "             'spread_': 12.156185908801568,\n",
       "             'S_': 0.013821675217155696,\n",
       "             'K_': -0.011450218486562073,\n",
       "             'T_': 0.15432477129479452,\n",
       "             'r_': 1.1450218486567054,\n",
       "             'sigma_': 0.741732418888659})"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "European_Adjoints = European_Option[2]\n",
    "European_Adjoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:27<00:00, 3641.73it/s]\n"
     ]
    }
   ],
   "source": [
    "TEST_European_Option = European_Option_Price_Adjoints_CVA(S0, K, T, r, sigma, n_simulations, n_steps, R, spread+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.37459020414506"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_European_CVA = TEST_European_Option[1]\n",
    "TEST_European_CVA - 0.23714567305942622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.156126105722365"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(CVA_Calculation(R, European_Price, spread+0.00000000001, T, n_steps).value - CVA_Calculation(R, European_Price, spread, T, n_steps).value)/0.00000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
